{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Python standard library : https://docs.python.org/3/library/ -------> distributed with Python\n",
    "##### PyPI - Python Package Index - https://pypi.org/ -----------> external modules to be downloaded and installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module namespace and module search path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports can be built-ins, or third party ones, or local application modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how import works - learn.py\n",
    "s1 = 'hello1'\n",
    "print(s1)\n",
    "def display():\n",
    "    print('hello')\n",
    "\n",
    "def main():\n",
    "    display()\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "    \n",
    "### importing only specific attributes\n",
    "from learn import display\n",
    "print(dir(learn))\n",
    "\n",
    "# Define main() function\n",
    "def main():\n",
    "    display('hello')\n",
    "    print(\"This is a main function\")\n",
    "\n",
    "# Execute main() function\n",
    "if __name__ == '__main__': # to avoid being called during module imports\n",
    "    main()\n",
    "    \n",
    "# module search path\n",
    "import sys\n",
    "print(sys.path)\n",
    "# appending a custom directory to module search path\n",
    "sys.path.append('D:\\\\PyCharm Projects\\\\Modules')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload - loading imports dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import learn2\n",
    "print(learn2.x)\n",
    "\n",
    "import time\n",
    "time.sleep(15)\n",
    "\n",
    "from importlib import reload\n",
    "reload(learn2)\n",
    "print(learn2.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string ::: creating unique password or account "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_rC[p[UT\n"
     ]
    }
   ],
   "source": [
    "# generating a random password using string module\n",
    "import string\n",
    "from random import *\n",
    "print(dir(string))\n",
    "characters = string.ascii_letters + string.punctuation  + string.digits\n",
    "password =  \"\".join(choice(characters) for x in range(randint(8, 16)))\n",
    "print (password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heapq ::: to find n smallest or n largest elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 37, 23, 23, 18]\n",
      "[-4, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "# usage 1\n",
    "nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]\n",
    "print(heapq.nlargest(5, nums)) # Prints [42, 37, 23]\n",
    "print(heapq.nsmallest(3, nums)) # Prints [-4, 1, 2]\n",
    "\n",
    "# usage 2\n",
    "portfolio = [\n",
    "{'name': 'IBM', 'shares': 100, 'price': 91.1},\n",
    "{'name': 'AAPL', 'shares': 50, 'price': 543.22},\n",
    "{'name': 'FB', 'shares': 200, 'price': 21.09},\n",
    "{'name': 'HPQ', 'shares': 35, 'price': 31.75},\n",
    "{'name': 'YHOO', 'shares': 45, 'price': 16.35},\n",
    "{'name': 'ACME', 'shares': 75, 'price': 115.65}\n",
    "]\n",
    "cheap = heapq.nsmallest(3, portfolio, key=lambda s: s['price'])\n",
    "expensive = heapq.nlargest(3, portfolio, key=lambda s: s['price'])\n",
    "\n",
    "# this is how heapq is implemented\n",
    "# stores the smallest element first\n",
    "nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]\n",
    "heap = list(nums)\n",
    "heapq.heapify(heap)\n",
    "for _ in range(len(heap)):\n",
    "    print(heapq.heappop(heap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sys ::: to parse arguments to script or modify I/O streams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# usage 1 : print Python version\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "# usage 2 : modules installed in custom directory\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('D:\\\\PyCharm Projects\\\\Modules')\n",
    "print(sys.path)\n",
    "\n",
    "# usage 3: argument processing\n",
    "import sys\n",
    "# it's easy to print this list of course:\n",
    "print sys.argv\n",
    "# or it can be iterated via a for loop:\n",
    "for i in range(len(sys.argv)):\n",
    "    if i == 0:\n",
    "        print \"Function name: %s\" % sys.argv[0]\n",
    "    else:\n",
    "        print \"%d. argument: %s\" % (i,sys.argv[i])\n",
    "\n",
    "# usage 4: I/O streams\n",
    "import sys\n",
    "for i in (sys.stdin, sys.stdout, sys.stderr):\n",
    "    print(i)\n",
    "    sys.stdout.write(\"Another way to do it!\\n\")\n",
    "\n",
    "# writing your errors & print statements to custom files\n",
    "import sys\n",
    "import traceback\n",
    "# save_stderr = sys.stderr\n",
    "ferr = open(\"errors2.txt\",\"w\")\n",
    "fout = open('standard_output.txt','w')\n",
    "sys.stderr = ferr\n",
    "sys.stdout = fout\n",
    "def divide_by_zero():\n",
    "    try:\n",
    "        print(2/0)\n",
    "    except:\n",
    "        print(traceback.print_exc(file=ferr))\n",
    "        print('divide by zero exception')\n",
    "\n",
    "def index_out_of_bounds():\n",
    "    try:\n",
    "        L1 = [1,2]\n",
    "        print(L1[100])\n",
    "    except:\n",
    "        print(traceback.print_exc(file=ferr))\n",
    "        print('index out of bounds exception')\n",
    "\n",
    "divide_by_zero()\n",
    "index_out_of_bounds()\n",
    "ferr.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glob ::: to search for files matching a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# glob usage : print all files and directories in a folder\n",
    "import glob\n",
    "import os\n",
    "for name in glob.glob('.\\*'):\n",
    "    if  os.path.isfile(name):\n",
    "        print ('File:',name)\n",
    "    if  os.path.isdir(name):\n",
    "        print ('Directory:',name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list contents of directory using listdir()\n",
    "os.listdir(<absolute path of directory>)\n",
    "\n",
    "# invoke commands in underlying os\n",
    "import os\n",
    "result = os.popen('ipconfig')\n",
    "print(''.join(result.readlines()))\n",
    "\n",
    "# walk a directory tree\n",
    "import os\n",
    "tree = os.walk('.')\n",
    "for _ in range(10):\n",
    "    print(next(tree))\n",
    "\n",
    "# file stats using os.stat()\n",
    "import os, time\n",
    "\n",
    "file_mod_time = time.ctime(os.stat(\"Agenda.txt\").st_mtime) # modification time\n",
    "file_mod_time_date_format = datetime.datetime.strptime(file_mod_time,'%c').strftime('%Y-%m-%d')\n",
    "print(file_mod_time_date_format)\n",
    "file_size = os.stat(\"Agenda.txt\").st_size # in bytes\n",
    "print(file_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display number of days for a month using calendar module\n",
    "\n",
    "import calendar\n",
    "months = list(range(1,13))\n",
    "cntr = 0\n",
    "monthData = {}\n",
    "for item in months:\n",
    "    cntr = cntr + 1\n",
    "    monthData[cntr] = calendar.monthrange(2018,item)[1]\n",
    "\n",
    "print(monthData)\n",
    "monthName = {'Jan':1,'Feb':2,'Mar':3,'Apr':4}\n",
    "print(monthName)\n",
    "\n",
    "inputMonth = input('Enter your month in 3 character format ; eg: Apr  :')\n",
    "\n",
    "print ('Number of days for',inputMonth,'is' ,monthData[monthName[inputMonth]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# count seconds since Epoch\n",
    "time.time()\n",
    "\n",
    "# convert seconds into readable representation\n",
    "time.ctime(<seconds elapsed since Epoch>)\n",
    "\n",
    "# sleep for specific seconds\n",
    "time.sleep(<seconds>)\n",
    "\n",
    "def sleeper():\n",
    "    while True:\n",
    "        # Get user input\n",
    "        num = input('How long to wait: ')\n",
    "\n",
    "        # Try to convert it to a float\n",
    "        try:\n",
    "            num = float(num)\n",
    "            if (num < 0):\n",
    "                raise ValueError(\"sleep length must be non-negative. Please enter in a number\")\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "        print('Before: ', time.ctime())\n",
    "        t1 = time.time()\n",
    "        time.sleep(num)\n",
    "        t2 = time.time()\n",
    "        print('After: ', time.ctime())\n",
    "        print('Diff is ',t2-t1)\n",
    "\n",
    "sleeper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# get today's date with time\n",
    "datetime.datetime.now()\n",
    "\n",
    "# or create a custom date object\n",
    "dt = datetime.datetime(2015, 10, 21, 16, 29, 0)\n",
    "dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second\n",
    "\n",
    "# convert UNIX epoch timestamp to a datetime object\n",
    "datetime.datetime.fromtimestamp(time.time())\n",
    "\n",
    "# comparing dates\n",
    "new_year = datetime.datetime(2019, 1, 1, 0, 0, 0)\n",
    "# current_year = datetime.datetime(2018, 12, 31, 0, 0, 0)\n",
    "current_year = datetime.datetime.now()\n",
    "\n",
    "new_year == current_year\n",
    "new_year - current_year\n",
    "\n",
    "# timedelta object to create a \"duration\" object\n",
    "delta = datetime.timedelta(days=11, hours=10, minutes=9, seconds=8)\n",
    "\n",
    "delta.days, delta.seconds, delta.microseconds,delta.total_seconds(), str(delta)\n",
    "\n",
    "# compute x days from now using timedelta object\n",
    "dt = datetime.datetime.now()\n",
    "thousandDays = datetime.timedelta(days=1000)\n",
    "dt + thousandDays\n",
    "\n",
    "# typecasting between date and string\n",
    "oct21st = datetime.datetime(2015, 10, 21, 16, 29, 0)\n",
    "oct21st.strftime('%Y/%m/%d %H:%M:%S')\n",
    "oct21st.strftime('%I:%M %p')\n",
    "oct21st.strftime(\"%B of '%y\")\n",
    "\n",
    "\n",
    "datetime.datetime.strptime('October 21, 2015', '%B %d, %Y')\n",
    "datetime.datetime.strptime(\"November of '63\", \"%B of '%y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "print(pytz.all_timezones)\n",
    "\n",
    "fmt = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "\n",
    "# Current time in UTC\n",
    "now_utc = datetime.now(pytz.timezone('UTC'))\n",
    "print(now_utc)\n",
    "now_mst = datetime.now(pytz.timezone('MST'))\n",
    "now_gmt = datetime.now(pytz.timezone('GMT'))\n",
    "now_est = datetime.now(pytz.timezone('EST'))\n",
    "\n",
    "print (now_utc.strftime(fmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "### usage 1\n",
    "\n",
    "def costly_func():\n",
    "   return map(lambda x: x^2, range(10))\n",
    "\n",
    "# timeit runs your snippet of code millions of time (default value is 1000000)\n",
    "# so that you get the statistically most relevant measurement of code execution time!\n",
    "print(timeit.timeit(costly_func))\n",
    "\n",
    "\n",
    "### usage 2\n",
    "mysetup = \"from math import sqrt\"\n",
    "# code snippet whose execution time is to be measured \n",
    "mycode = ''' \n",
    "def example(): \n",
    "    mylist = [] \n",
    "    for x in range(100): \n",
    "        mylist.append(sqrt(x)) \n",
    "'''\n",
    "\n",
    "# number denotes the number of iterations the code snipppet will be measured - can be customized\n",
    "print(\n",
    "    timeit.timeit(setup=mysetup,\n",
    "              stmt=mycode,\n",
    "              number=1000) \n",
    ")\n",
    "\n",
    "\n",
    "### usage 3\n",
    "def classic_usage():\n",
    "    import math\n",
    "    L = []\n",
    "    for i in range(100000):\n",
    "        L.append(i)\n",
    "\n",
    "def comprehension_usage():\n",
    "    import math\n",
    "    L = []\n",
    "    [L.append(math.sqrt(i)) for i in range(100000)]\n",
    "\n",
    "# print(__name__)\n",
    "if __name__ == '__main__':\n",
    "    import timeit\n",
    "    for function_obj in ['classic_usage()','comprehension_usage()']:\n",
    "        results = timeit.repeat(stmt=function_obj, number=1000, repeat=3,setup=\"from __main__ import classic_usage,comprehension_usage\")\n",
    "        print(sum(results)/len(results))\n",
    "\n",
    "# print(eval('classic_usage()'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filecmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import filecmp\n",
    "import os\n",
    "\n",
    "# file comparision\n",
    "file1 = r'C:\\Users\\Manojkumar.Rajendran\\Desktop\\tmp\\tmp1\\file1.txt'\n",
    "file2 = r'C:\\Users\\Manojkumar.Rajendran\\Desktop\\tmp\\tmp1\\file2.txt'\n",
    "\n",
    "print(filecmp.cmp(file1,file2))\n",
    "\n",
    "# directory comparision\n",
    "referenceDir = r'C:\\Users\\Manojkumar.Rajendran\\Desktop\\tmp\\tmp1'\n",
    "dirToCompare = r'C:\\Users\\Manojkumar.Rajendran\\Desktop\\tmp\\tmp2'\n",
    "\n",
    "dcmp = filecmp.dircmp(referenceDir, dirToCompare)\n",
    "print ('Files changed in',referenceDir,'are',dcmp.diff_files)\n",
    "print ('Common files present in both directory are',dcmp.same_files)\n",
    "dcmp.report()\n",
    "print(dcmp.left_list,dcmp.right_list)\n",
    "\n",
    "for item in os.listdir(referenceDir):\n",
    "    if os.path.isdir(referenceDir+'\\\\'+item) and os.path.isdir(dirToCompare+'\\\\'+item):\n",
    "        dcmp = filecmp.dircmp(referenceDir+'\\\\'+item, dirToCompare+'\\\\'+item)\n",
    "        print ('Files changed in',item,'are',dcmp.diff_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "print(type(uuid.UUID('06335e84-2872-4914-8c5d-3ed07d2a2f16')))\n",
    "x = uuid.uuid4()\n",
    "print(str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas ::: for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dir = r'C:\\Users\\Manojkumar.Rajendran\\Desktop\\tmp'\n",
    "# read csv using pandas method\n",
    "titanic  = pd.read_csv(dir+'\\\\'+'titanic.csv')\n",
    "# or read csv only with required columns\n",
    "titanic  = pd.read_csv(dir+'\\\\'+'titanic.csv',usecols=['Name','Age'])\n",
    "# count the number of records\n",
    "print(len(titanic))\n",
    "print the values\n",
    "print(titanic.values) # titanic.values is a list\n",
    "# get first record\n",
    "print(titanic.values[0],titanic.values[0][0])\n",
    "# get top 5 records\n",
    "print(titanic.head())\n",
    "# get records specified by a custom range\n",
    "print(titanic.ix[50:100:5])\n",
    "# get column names\n",
    "print(titanic.columns,list(titanic.columns))\n",
    "# get all rows of a column\n",
    "print(titanic['Name'],titanic['Name'].values,list(titanic['Name'].values))\n",
    "# pattern matching for a specific value\n",
    "names = list(titanic['Name'].values)\n",
    "\n",
    "# import re\n",
    "pattern = re.compile(r'Allison')\n",
    "result = [bool(pattern.search(name)) for name in names]\n",
    "print(len([item for item in result if item == True]))\n",
    "# filter records > a value\n",
    "age_filter = list(titanic['Age'] > 50)\n",
    "print(len([item for item in age_filter if item == True]))\n",
    "# apply filter to the dataframe\n",
    "print( titanic[titanic['Age'] > 50])\n",
    "# or multiple filters at once\n",
    "age_filter = list((titanic['Age'] > 50) | (titanic['Age'] > 30))\n",
    "print(len([item for item in age_filter if item == True]))\n",
    "# get distinct values of a column\n",
    "print(list(titanic['Class'].unique()))\n",
    "# replace NaN values with 0 - by default it treats number as float - all invalid floats are NaN\n",
    "titanic = titanic.fillna(0)\n",
    "print(titanic['Age'])\n",
    "# replace column values at one shot using batch operation - do an inplace edit\n",
    "titanic.ix[:,'Age'] = [int(item) for item in titanic['Age']]\n",
    "# apply a function to specific values\n",
    "titanic.ix[:,'Gender'] = [item.upper() for item in titanic['Gender']]\n",
    "print(list(titanic['Gender'].unique()))\n",
    "# replace certain values in a column\n",
    "titanic['Class'] =  titanic['Class'].map({1:'Class1',2:'Class2',3:'Class3'})\n",
    "print(list(titanic['Class'].unique()))\n",
    "# get a subset of dataframe\n",
    "titanic = titanic[titanic['Age'] > 70]\n",
    "print(len(titanic))\n",
    "\n",
    "# store all the changes to a csv\n",
    "titanic.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# another usage of pandas\n",
    "path = r'D:\\PyCharmProjects\\Input data'\n",
    "import pandas as pd\n",
    "\n",
    "aadhar = pd.read_csv(path+'\\\\'+'aadhar.csv')\n",
    "name = input('Enter the name to check:')\n",
    "indexes = [index for index,value in enumerate(list(aadhar['name'].values)) if name == value]\n",
    "\n",
    "print('Frequency of name given as input:',len(aadhar.ix[indexes,'name']))\n",
    "print('Ids are',aadhar.ix[indexes,[0,1]])\n",
    "\n",
    "cols = []\n",
    "for item in aadhar.columns:\n",
    "    print('<',item,'>')\n",
    "    item = item.strip()\n",
    "    cols.append(item)\n",
    "\n",
    "aadhar.columns = cols\n",
    "\n",
    "yob = input('Enter the yob to check:')\n",
    "indexes = [index for index,value in enumerate(list(aadhar['yob'].values)) if float(yob) == value]\n",
    "print(indexes)\n",
    "yob_values = aadhar.ix[indexes,'yob'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read and write to excel using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ read excel workbook\n",
    "\n",
    "# using pandas read_excel\n",
    "path = r'C:\\Users\\Manojkumar.Rajendran\\Desktop\\tmp'\n",
    "df = pd.read_excel(path+'\\\\'+'training_template.xlsx', sheetname = '2017-18 TRD')\n",
    "\n",
    "# or by pandas ExcelFile object\n",
    "\n",
    "# Load spreadsheet\n",
    "xl = pd.ExcelFile(path+'\\\\'+'training_template.xlsx')\n",
    "\n",
    "# Print the sheet names\n",
    "print(xl.sheet_names)\n",
    "\n",
    "# Load a sheet into a DataFrame by name: df1\n",
    "df1 = xl.parse(xl.sheet_names[0])\n",
    "\n",
    "############# write to excel workbook \n",
    "# prerequisites : XlsxWriter module\n",
    "\n",
    "# Specify a writer\n",
    "writer = pd.ExcelWriter('example.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Write your DataFrame to a file     \n",
    "yourData.to_excel(writer, 'Sheet1')\n",
    "\n",
    "# Save the result \n",
    "writer.save()\n",
    "\n",
    "########### for more usage, hit this url\n",
    "# https://www.datacamp.com/community/tutorials/python-excel-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read tables from pdf using tabula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-requisites : install tabula and tabula-py\n",
    "from tabula import read_pdf\n",
    "path = r'D:\\PyCharmProjects\\Input data'\n",
    "\n",
    "# bang! - you get a dataframe\n",
    "output = read_pdf(path+'\\\\'+'ast_sci_data_tables_sample.pdf',pages=[1,2],multiple_tables=True)\n",
    "df1 = output[0]\n",
    "df2 = output[1]\n",
    "df3 = output[2]\n",
    "\n",
    "# play with dataframe and store it to csv!\n",
    "df1.drop(0,axis=0,inplace=True)\n",
    "df1.columns = ['NumberOfCoils','NumberOfPaperClips']\n",
    "df1.to_csv('df1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read/write to xml and html using xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################### read/write to xml\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "path = r'M:\\PythonSpace\\Datasets'\n",
    "tree = ET.parse(path+'\\\\'+'books.xml') \n",
    "\n",
    "# get the catalog\n",
    "root = tree.getroot()\n",
    "print(root.tag, root.attrib,root.text)\n",
    "\n",
    "# traverse the catalog recursively\n",
    "for child in root:\n",
    "    print(child.tag, child.attrib,child.text)\n",
    "    for subchild in child:\n",
    "        print(subchild.tag, subchild.attrib,subchild.text)\n",
    "\n",
    "# get all book titles\n",
    "for title in root.iter('title'):\n",
    "    print(title.tag, title.attrib, title.text)\n",
    "\n",
    "# get details of specific book \n",
    "for child in root:\n",
    "    if child.attrib['id'] == 'bk101':\n",
    "        print(child.tag, child.attrib,child.text)\n",
    "        for subchild in child:\n",
    "            print(subchild.tag, subchild.attrib,subchild.text)\n",
    "\n",
    "# find books which doesn't have author\n",
    "for book in root.iter('book'):\n",
    "    author = book.find('author')\n",
    "    if author is None:\n",
    "        print('The book', book.attrib['id'], 'does not contain author')\n",
    "    else:\n",
    "        print(author.tag,author.attrib,author.text)\n",
    "\n",
    "        \n",
    "# update price for books written by specific author\n",
    "for book in root.iter('book'):\n",
    "    author = book.find('author')\n",
    "    if author.text == 'Corets, Eva':\n",
    "        price = book.find('price')\n",
    "        print(price.tag, price.text)\n",
    "        price.text = float(price.text) * 2.0 \n",
    "\n",
    "# remove publish_date for all books written by specific author\n",
    "for book in root.iter('book'):\n",
    "    author = book.find('author')\n",
    "    if author.text == 'Corets, Eva':\n",
    "        publish_date = book.find('publish_date')\n",
    "        book.remove(publish_date)        \n",
    "\n",
    "# save the changes to xml\n",
    "tree.write(path+'\\\\'+'modified.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### itertools - a module with advanced iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### itertools.groupby ::: Grouping Records Together Based on a Field \n",
    "\n",
    "rows = [\n",
    "{'address': '5412 N CLARK', 'date': '07/01/2012'},\n",
    "{'address': '5148 N CLARK', 'date': '07/04/2012'},\n",
    "{'address': '5800 E 58TH', 'date': '07/02/2012'},\n",
    "{'address': '2122 N CLARK', 'date': '07/03/2012'},\n",
    "{'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'},\n",
    "{'address': '1060 W ADDISON', 'date': '07/02/2012'},\n",
    "{'address': '4801 N BROADWAY', 'date': '07/01/2012'},\n",
    "{'address': '1039 W GRANVILLE', 'date': '07/04/2012'},\n",
    "]\n",
    "\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "# An important preliminary step is sorting the data according to the field of interest. Since\n",
    "# groupby() only examines consecutive items, failing to sort first won’t group the records\n",
    "# as you want.\n",
    "rows.sort(key=itemgetter('date'))\n",
    "\n",
    "# Iterate in groups\n",
    "for date, items in groupby(rows, key=itemgetter('date')):\n",
    "    print(date)\n",
    "    for i in items:\n",
    "        print(' ', i)\n",
    "\n",
    "# second example\n",
    "\n",
    "inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]\n",
    "getcount = itemgetter(1)\n",
    "\n",
    "print(list(map(getcount, inventory)))\n",
    "print(sorted(inventory, key=getcount))\n",
    "\n",
    "        \n",
    "### permuatations,combinations,chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "--- wildcards  ---\n",
    "The ? matches zero or one of the preceding group.\n",
    "The * matches zero or more of the preceding group.\n",
    "The + matches one or more of the preceding group.\n",
    "The {n} matches exactly n of the preceding group.\n",
    "The {n,} matches n or more of the preceding group.\n",
    "The {,m} matches 0 to m of the preceding group.\n",
    "The {n,m} matches at least n and at most m of the preceding group.\n",
    "{n,m}? or *? or +? performs a nongreedy match of the preceding group.\n",
    "^(spam) means the string must begin with s.\n",
    "(spam)$ means the string must end with spam.\n",
    "The . matches any character, except newline characters.\n",
    "[abc] matches any character between the brackets (such as a, b, or c).\n",
    "[^abc] matches any character that isn’t between the brackets.\n",
    "\n",
    "--- Character classes and shortcuts ----\n",
    "# \\d - [0-9]\n",
    "# \\w - [a-zA-Z0-9_]\n",
    "# \\s - [ \\t\\r\\n\\f]\n",
    "# \\D - [^\\d] - match any character other than a number\n",
    "# \\W - [^\\w]\n",
    "\n",
    "# \\S - [^\\s]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# re.compile() , re.search and group() - compile the pattern using compile, check for successful pattern match using search\n",
    "import re\n",
    "patternStr = re.compile(r'Hello[ \\t]*(.*)world') # first, compile the pattern\n",
    "str1 = 'Hello Python world' # second, define the string\n",
    "match = patternStr.search(str1) # third, search pattern in the string\n",
    "if (match is not None): # fourth, check if pattern match is successful\n",
    "    print ('Yes,matched')\n",
    "    match.group()\n",
    "\n",
    "# re.findall() - get all the matched parts \n",
    "xx = \"guru99,education is fun\"\n",
    "words = re.findall(r\"\\w+\",xx) # get all the words from a string\n",
    "first_word = re.findall(r\"^\\w+\",xx) # get only the first word\n",
    "print(words,first_word)\n",
    "\n",
    "# re.findall() - get all words from a file\n",
    "path = r'D:\\PyCharmProjects\\Input data'\n",
    "file_input = open(path+'\\\\'+'aadhar.txt')\n",
    "words = re.findall(r'\\w+', file_input.read().lower())\n",
    "file_input.close()\n",
    "\n",
    "# re.findall() - to find multiple occurrences of a pattern\n",
    "import re\n",
    "str1 = '''Welcome to Python training. Python is one of the most sought-after languages today. \n",
    "You can make a great contribution to society using Python by building powerful and simple apps.\n",
    "So, start learning Python today'''\n",
    "words = re.findall(r'(.*)Python(.*)',str1,re.MULTILINE) # get all the occurrences of a pattern\n",
    "\n",
    "# re.findall() - get all non-vowel words\n",
    "import re\n",
    "message = '''Welcome to Python training. Python is one of the most sought-after languages today.\n",
    "You can make a great contribution to society using Python by building powerful and simple apps.\n",
    "So, start learning Python today rhythm '''\n",
    "words = re.findall(r'\\s[^aeiou]*\\s',message) # get all the occurrences of a pattern\n",
    "\n",
    "# re.split - split the file with the pattern\n",
    "file_input = open(path+'\\\\'+'aadhar.txt')\n",
    "lines = re.split(r'\\s', file_input.read().lower())\n",
    "\n",
    "# groups() - memory captures\n",
    "import re\n",
    "str_message = 'an example word:cat!!'\n",
    "match = re.search(r'word:(\\w)(\\w)\\w', str_message)\n",
    "# If-statement after search() tests if it succeeded\n",
    "if match:\n",
    "    print ('found', match.groups()) ## 'found word:cat'\n",
    "else:\n",
    "    print ('did not find')\n",
    "    \n",
    "# re.sub() - replacing matched pattern with replacement\n",
    "phone_number = '6267890123'\n",
    "phone_number = re.sub(r'(\\d{3})(\\d{3})(\\d{4})',r'(\\1)-\\2-\\3',phone_number)\n",
    "\n",
    "\n",
    "# re.DOTALL to match multi lines of string\n",
    "import re\n",
    "import pandas as pd\n",
    "path = r'D:\\PyCharmProjects\\Input data'\n",
    "file_input = open(path+'\\\\'+'liquid_data.txt')\n",
    "file_string = file_input.read()\n",
    "matches = re.search(r'(pattern1)(.*)(pattern2)(.*)', file_string,re.DOTALL)\n",
    "cnt = 1\n",
    "rows_values = []\n",
    "cols_values = []\n",
    "table = {}\n",
    "for item in matches.groups():\n",
    "    if cnt % 2 == 0:\n",
    "        rows_values.append([item.replace('\\n','')])\n",
    "    else:\n",
    "        cols_values.append(item)\n",
    "    cnt = cnt + 1\n",
    "table = table.fromkeys(cols_values)\n",
    "for key,value in table.items():\n",
    "    for item in rows_values:\n",
    "        table[key] = item\n",
    "data_formatted = pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use case 1 - password validation using re\n",
    "import re\n",
    "while True:\n",
    "    print ('--------')\n",
    "    uid = input (\"Enter your username:\")\n",
    "    if uid == 'stop':\n",
    "        print ('stop given. exiting...')\n",
    "        break\n",
    "\n",
    "    if len(uid) >= 8:\n",
    "        pwd = input(\"Enter your pwd:\")\n",
    "        while True :\n",
    "            if len(pwd) < 8:\n",
    "                print('Length should atleast be 8')\n",
    "                pwd = input(\"Enter your pwd:\")\n",
    "            elif bool(re.search(r'\\d', pwd)) is False:\n",
    "                print('Pwd should contain atleast a number')\n",
    "                pwd = input(\"Enter your pwd:\")\n",
    "            else :\n",
    "                print ('Your password is strong')\n",
    "                break\n",
    "\n",
    "    else :\n",
    "        print('Length should atleast be 8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use case 2 - telephone directory using re\n",
    "import re\n",
    "fout = open('telephone_dir','w')\n",
    "fout.write('name,phone,country'+'\\n')\n",
    "while True :\n",
    "    personal_info = input('Enter your name and phone number :')\n",
    "    if personal_info == 'stop':\n",
    "        break\n",
    "    pattern_of_ind = re.compile(r'.*\\d{10}.*',re.IGNORECASE) # case-insensitive match of a pattern contiguously placed\n",
    "    pattern_of_us = re.compile(r'.*\\d{3}-\\d{3}-\\d{4}.*',re.IGNORECASE) # case-insensitive match of a pattern contiguously place\n",
    "    if pattern_of_ind.search(personal_info):\n",
    "        name,phone = personal_info.split(',')\n",
    "        fout.write(name+','+phone+','+'India'+'\\n')\n",
    "    elif pattern_of_us.search(personal_info):\n",
    "        name, phone = personal_info.split(',')\n",
    "        fout.write(name+','+phone+','+'USA'+'\\n')\n",
    "    else :\n",
    "        name, phone = personal_info.split(',')\n",
    "        fout.write(name + ',' + phone + ',' + 'Others' + '\\n')\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use case 3 - analyze structured data with help of regular expressions\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "path = r'D:\\PyCharmProjects\\Input data'\n",
    "e_commerce_data = pd.read_csv(os.path.join(path,'Ecommerce_Customers.csv'))\n",
    "\n",
    "# sort df by a column\n",
    "e_commerce_data.sort_values(by=['Email'],inplace=True)\n",
    "\n",
    "# remove new line character in address column\n",
    "e_commerce_data['Address'] = [address.replace('\\n',' ') for address in e_commerce_data['Address']] \n",
    "\n",
    "# filter addresses with a hyphen\n",
    "def filter_hyphen(address):\n",
    "    match = re.search('\\d*-\\d*',address)\n",
    "    if match is not None:\n",
    "        print(match.group())\n",
    "        return True, match.group()\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "hyphen_mask = [filter_hyphen(address) for address in e_commerce_data['Address']]\n",
    "\n",
    "\n",
    "def find_all_words(address):\n",
    "    # find all alphabetic words\n",
    "    alpha_words = re.findall(r'[a-zA-Z]+',address)\n",
    "    # split string based on a space\n",
    "    words = re.split(r'\\s*',address)\n",
    "    # find all numeric words\n",
    "    number_words = re.findall(r'\\d+',address)\n",
    "    # find all numeric words occurring after alpha words\n",
    "    match = re.search(r'[a-zA-Z]+\\s*(\\d*)$', address)\n",
    "    if match:\n",
    "        number_word_after_alpha = match.groups()\n",
    "    else:\n",
    "        number_word_after_alpha = None\n",
    "    return alpha_words, words, number_words,number_word_after_alpha    \n",
    "\n",
    "print([find_all_words(address) for address in e_commerce_data['Address']])\n",
    "\n",
    "def replace_hyphen_with_slash(address):\n",
    "    # substitute hyphenated words with a /\n",
    "    match = re.search('\\d*-\\d*',address)\n",
    "    if match:\n",
    "        replaced_address = re.sub(r'(\\d*)-(\\d*)',r'\\1/\\2',address)\n",
    "        return replaced_address\n",
    "    else:\n",
    "        return address\n",
    "    \n",
    "\n",
    "e_commerce_data['Address'] = [replace_hyphen_with_slash(address) for address in e_commerce_data['Address']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### object serialization - a.k.a object storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = list(range(1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op_file = open('file1.pkl','wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(l1,op_file)\n",
    "op_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_file = open('file1.pkl','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_load = pickle.load(ip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(l1_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading and modifying json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r'D:\\PyCharmProjects\\Input data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_file = open(path+'\\\\'+'youtube.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "youtube = json.loads(ip_file) # what you get is a dictionary\n",
    "# json.loads(<string>) converts a string containing a json into a dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ip_file.close()\n",
    "print(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "youtube['kind'] = youtube['kind']+' hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op_file = open(path+'\\\\'+'youtube.json','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dumps(youtube,op_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using pandas to read json\n",
    "json_string = \"\"\"{\n",
    "\"name\": [\"python\",\"java\",\"c\",\"c++\",\"perl\",\"unix\",\"linux\",\"windows\",\"ms-dos\",\"ruby\",\".net\"],\n",
    "\"year\": [1990,1995,1972,1985,1987,1969,1991,1985,1981,1995,2002]\n",
    "}\"\"\"\n",
    "\n",
    "df = pd.read_json(json_string)\n",
    "# convert dataframe to json object\n",
    "df.to_json()\n",
    "# to_json orient attribute has index,values,columns,tables,records and split\n",
    "df.to_json(orient='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple usage of logging\n",
    "import logging\n",
    "\n",
    "# by default prints to console\n",
    "logging.debug('This message should go to the log file')\n",
    "logging.info('So should this')\n",
    "logging.warning('And this, too')\n",
    "logging.error('error')\n",
    "logging.critical('critical')\n",
    "\n",
    "# NOTE #\n",
    "# level can be DEBUG,INFO,WARNING,ERROR,CRITICAL\n",
    "# attributes that can be used for format : https://docs.python.org/3/library/logging.html#logrecord-attributes\n",
    "\n",
    "\n",
    "# writing exceptions caught in a log file using exception method in logging object\n",
    "a = 5\n",
    "b = 0\n",
    "try:\n",
    "  c = a / b\n",
    "except Exception as e:\n",
    "  logging.exception(\"Exception occurred\")\n",
    "\n",
    "\n",
    "### using a generic function to create multiple logging objects\n",
    "import logging\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "def setup_logger(name, log_file, level=logging.INFO):\n",
    "    \"\"\"Function setup as many loggers as you want\"\"\"\n",
    "\n",
    "    logger = logging.getLogger(name) # gets a custom logger name\n",
    "    handler = logging.FileHandler(log_file) # opens a file for writing and returns a file handler\n",
    "    handler.setFormatter(formatter) # formats the message for logging using the format specified\n",
    "    logger.setLevel(level) # sets the severity of logging message\n",
    "    logger.addHandler(handler) # adds the file handler to logging root\n",
    "\n",
    "    return logger\n",
    "\n",
    "# custom logger 1\n",
    "# get name of script use that as log file name\n",
    "# log_file = __file__.split('/')[-1].split('.')[0]\n",
    "# log_file = log_file + '.log'\n",
    "\n",
    "logger = setup_logger('first_logger', 'first_logfile.log', logging.WARNING)\n",
    "logger.info('This is just info message')\n",
    "\n",
    "# custom logger 2\n",
    "super_logger = setup_logger('second_logger', 'second_logfile.log', logging.CRITICAL)\n",
    "super_logger.error('This is an error message')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smtplib - to send emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################## Sending plain emails using Python\n",
    "\n",
    "'''\n",
    "Google blocks sign-in attempts from apps which do not use modern security standards (mentioned on their support page). \n",
    "You can however, turn on/off this safety feature by going to the link below:\n",
    "Go to this link and select Turn On\n",
    "https://www.google.com/settings/security/lesssecureapps\n",
    "'''\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "\n",
    "smtp_server = 'smtp.gmail.com'\n",
    "smtp_port = 587\n",
    "\n",
    "user = 'manojkumar.robust@gmail.com'\n",
    "password = r\"Mano@111085\"\n",
    "receiver_email = 'manojkumar.robust@gmail.com,saurabh57@gmail.com,shyamkumar.chauhan@gmail.com,govindgoyal11@gmail.com'\n",
    "\n",
    "subject = 'Subject: ' + 'Test email'\n",
    "body = 'Test email using Python'\n",
    "message = subject + str('\\n' * 2) + body\n",
    "\n",
    "with smtplib.SMTP(smtp_server,smtp_port) as smtp_session:\n",
    "    smtp_session.starttls(context=context)\n",
    "    smtp_session.ehlo()\n",
    "    smtp_session.login(user,password)\n",
    "    for to_address in receiver_email.split(','):\n",
    "        smtp_session.sendmail(user,to_address,message)\n",
    "\n",
    "\n",
    "######################################### sending HTML content in emails  \n",
    "\n",
    "import smtplib, ssl\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "sender_email = ''\n",
    "receiver_email = ''\n",
    "password = ''\n",
    "\n",
    "smtp_server = ''\n",
    "smtp_port = ''\n",
    "\n",
    "message = MIMEMultipart(\"alternative\")\n",
    "message[\"Subject\"] = \"Testing\"\n",
    "message[\"From\"] = sender_email\n",
    "message[\"To\"] = receiver_email\n",
    "\n",
    "html = \"\"\"\\\n",
    "<html>\n",
    "  <body>\n",
    "    <p>Guess me - I'm an info aggregator.<br>\n",
    "       Whom am I ?<br>\n",
    "       <a href=\"http://www.google.com\">Click it to find out</a> \n",
    "    </p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Turn these into plain/html MIMEText objects\n",
    "html_message = MIMEText(html, \"html\")\n",
    "\n",
    "# Add HTML/plain-text parts to MIMEMultipart message\n",
    "# The email client will try to render the last part first\n",
    "message.attach(html_message)\n",
    "\n",
    "# Create secure connection with server and send email\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP(smtp_server,smtp_port) as smtp_session:\n",
    "    smtp_session.starttls(context=context)\n",
    "    smtp_session.login(sender_email, password)\n",
    "    smtp_session.sendmail(\n",
    "        sender_email, receiver_email, message.as_string()\n",
    "    )\n",
    "\n",
    "\n",
    "############################################ sending attachments in emails\n",
    "\n",
    "import email, smtplib, ssl\n",
    "import os\n",
    "\n",
    "from email import encoders\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "subject = \"An email with attachment from Python\"\n",
    "body = \"This is an email with attachment sent from Python\"\n",
    "sender_email = \"\"\n",
    "receiver_email = \"\"\n",
    "password = \"\"\n",
    "\n",
    "smtp_server = ''\n",
    "smtp_port = ''\n",
    "\n",
    "# Create a multipart message and set headers\n",
    "message = MIMEMultipart()\n",
    "message[\"From\"] = sender_email\n",
    "message[\"To\"] = receiver_email\n",
    "message[\"Subject\"] = subject\n",
    "message[\"Bcc\"] = receiver_email  # Recommended for mass emails\n",
    "\n",
    "# Add body to email\n",
    "message.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "filename = '<absolute path of file>'\n",
    "\n",
    "# Open PDF file in binary mode\n",
    "with open(filename, \"rb\") as attachment:\n",
    "    # Add file as application/octet-stream\n",
    "    # Email client can usually download this automatically as attachment\n",
    "    part = MIMEBase(\"application\", \"octet-stream\")\n",
    "    part.set_payload(attachment.read())\n",
    "\n",
    "# Encode file in ASCII characters to send by email\n",
    "encoders.encode_base64(part)\n",
    "\n",
    "# Add header as key/value pair to attachment part\n",
    "part.add_header(\n",
    "    \"Content-Disposition\",\n",
    "    \"attachment; filename= {}\".format(os.path.basename(filename)),\n",
    ")\n",
    "\n",
    "# Add attachment to message and convert message to string\n",
    "message.attach(part)\n",
    "text = message.as_string()\n",
    "\n",
    "# Log in to server using secure context and send email\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP(smtp_server,smtp_port) as smtp_session:\n",
    "    smtp_session.starttls(context=context)\n",
    "    smtp_session.login(sender_email, password)\n",
    "    smtp_session.sendmail(sender_email, receiver_email, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collections - advanced containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n1', 4), ('id1', 3), ('2080', 2), ('id2', 2), ('n2', 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counter\n",
    "import re\n",
    "path = r'D:\\PyCharmProjects\\Input data'\n",
    "cnt = Counter()\n",
    "file_input = open(path+'\\\\'+'aadhar.txt')\n",
    "words = re.findall(r'\\w+', file_input.read().lower())\n",
    "cnt = Counter(words)\n",
    "cnt.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read and write to postgres database using pandas read_sql and to_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc\n",
    "import os\n",
    "import datetime\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "\n",
    "config = {\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "    'host': '127.0.0.1',\n",
    "    'port': '5432',\n",
    "    'database': 'postgres'\n",
    "}\n",
    "\n",
    "def archiveAndRefresh() :\n",
    "    try :\n",
    "        loan_data.to_sql(name='loan_data', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    except (exc.DatabaseError,exc.OperationalError):\n",
    "        print(traceback.print_exc(file=sys.stdout))\n",
    "    \n",
    "    finally:\n",
    "        if engine is not None:\n",
    "            engine.dispose()\n",
    "\n",
    "path = r'D:\\PythonSpace\\Input_Data'\n",
    "loan_data = pd.read_csv(os.path.join(path,'loan_data.csv'))\n",
    "print(loan_data)\n",
    "\n",
    "# ====== Connection ======\n",
    "# Connecting to PostgreSQL by providing a sqlachemy engine\n",
    "engine = create_engine('postgresql://'+config['user']+':'+config['password']+'@'+config['host']+':'+config['port']+'/'+config['database'],echo=False)\n",
    "print(engine)\n",
    "archiveAndRefresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### OpenNotify API - public API released by NASA\n",
    "\n",
    "import requests\n",
    "\n",
    "# Usage 1\n",
    "# Open Notify API from NASA\n",
    "# a API url consist of base URL and endpoint\n",
    "url = \"http://api.open-notify.org/iss-now.json\"\n",
    "\n",
    "# a GET request to API\n",
    "response = requests.get(url)\n",
    "\n",
    "# attributes of Response object\n",
    "print(response.status_code)\n",
    "print(response.content)\n",
    "print(response.content.decode(\"utf-8\")) # returns a string\n",
    "print(response.json()) # returns a json\n",
    "print(response.headers) # metadata containing information on how the data was generated and how to decode it\n",
    "\n",
    "# Usage 2 - pass parameters\n",
    "parameters = {\"lat\": 40.71, \"lon\": -74}\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\",params=parameters)\n",
    "\n",
    "\n",
    "#### ipstack - to know the visitor information of a website\n",
    "\n",
    "import os\n",
    "import requests\n",
    "for line in os.popen('ipconfig').readlines():\n",
    "    if 'IPv4' in line:\n",
    "        ipv4_address = line.split(':')[1].strip()\n",
    "print('your ipv4 address is',ipv4_address)\n",
    "\n",
    "my_public_ip = '122.174.118.161'\n",
    "public_access_key = r'711e77a8fb1aa664dc6409e77ab04f69'\n",
    "base_url = r'http://api.ipstack.com/' + my_public_ip + r'?access_key=' + public_access_key + r'&format=1'\n",
    "response = requests.get(url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def parse_html(url):\n",
    "    \n",
    "    page = requests.get(url) # download page \n",
    "    if page.status_code == 200: # meaning the download is successful\n",
    "        soup = BeautifulSoup(page.content, 'html.parser') # parse the downloaded page in html format\n",
    "    print(soup)\n",
    "    print(soup.prettify())\n",
    "    \n",
    "    # locating a tag with tag name and extracting content\n",
    "    title = soup.find('title')\n",
    "    title.text\n",
    "    \n",
    "    # locating all tags\n",
    "    soup.findAll('div')\n",
    "    \n",
    "    # locating tag by its name and attribute\n",
    "    soup.find('div',attrs={'id':'mw-head-base'})\n",
    "    \n",
    "    # traversing the entire html\n",
    "    [type(item) for item in list(soup.children)] # navigate the html tree\n",
    "    html = list(soup.children)[2]\n",
    "    \n",
    "    [type(item) for item in list(html.children)]\n",
    "    head = list(html.children)[1]\n",
    "    \n",
    "    [type(item) for item in list(head.children)]\n",
    "    body = list(html.children)[3]\n",
    "    \n",
    "    [type(item) for item in list(body.children)]\n",
    "\n",
    "    # extract the table and convert to dataframe\n",
    "    table_html = soup.find_all('table')[2]\n",
    "    convert_to_df(str(table_html))\n",
    "    \n",
    "def convert_to_df(table_html):\n",
    "    dataframes = pd.read_html(table_html)\n",
    "    #or pass directly the url and get all tables from <table> tag in html\n",
    "#     dataframes = pd.read_html(url)\n",
    "    print(dataframes)\n",
    "#     states_df.columns = ['State','ISO','Vehicle Code','Zone','Capital','Largest city','Statehood','Population','Area','Official Languages','Additional official languages']\n",
    "\n",
    "\n",
    "# url = 'https://en.wikipedia.org/wiki/States_and_union_territories_of_India'\n",
    "# url = 'http://finance.yahoo.com/quote/AMZN?p=AMZN'\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_state_and_union_territory_capitals_in_India'\n",
    "parse_html(url)\n",
    "    \n",
    "# second example\n",
    "def fetch(t):\n",
    "    url = f'http://finance.yahoo.com/quote/{t}?p={t}'\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    table = soup.find_all('table')[0]\n",
    "    labels, data = pd.read_html(str(table))[0].values.T\n",
    "    return pd.Series(data, labels, name=t)\n",
    "\n",
    "tickers = [\"AAPL\",\"AMZN\", \"INTC\", \"MSFT\", \"SNAP\"]\n",
    "df = pd.concat(map(fetch, tickers), axis=1)\n",
    "print(df)\n",
    "    \n",
    "########### for more usage, hit this url\n",
    "#https://www.dataquest.io/blog/web-scraping-tutorial-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import traceback\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('aws_automation')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stream_handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "def create_instance(ami_id,size='t2.micro'):\n",
    "    try:\n",
    "        print(ami_id,size)\n",
    "        instance = ec2.create_instances(\n",
    "            ImageId=ami_id, # free-tier Linux AMI\n",
    "            MinCount=1,\n",
    "            MaxCount=1,\n",
    "            InstanceType=size)\n",
    "        \n",
    "        return instance\n",
    "    except:\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        return None\n",
    "\n",
    "\n",
    "def terminate_instance(instance_id):\n",
    "    instance = ec2.Instance(instance_id)\n",
    "    result = instance.terminate()\n",
    "    print(result)\n",
    "\n",
    "def create_bucket(bucket_name):\n",
    "    import datetime\n",
    "    print(s3)\n",
    "    today_date = datetime.datetime.today().strftime('%Y-%d-%m')\n",
    "    bucket_name = bucket_name + '-' + today_date\n",
    "    result = s3.create_bucket(\n",
    "                                Bucket=bucket_name,\n",
    "                                CreateBucketConfiguration={'LocationConstraint': 'us-east-2'}\n",
    "                                )\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def upload_objects_to_s3():\n",
    "    from pathlib import WindowsPath\n",
    "    path = WindowsPath(r'D:\\PyCharmProjects\\Input data')\n",
    "    object_name = str(path / 'advertising.csv')\n",
    "    print(object_name)\n",
    "    response = s3.Object(result.name, object_name).put(Body=open(str(object_name), 'rb'))\n",
    "    print(response)\n",
    "    \n",
    "\n",
    "try:\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id='AKIA4LFWAZSZPYX6S6NE', \n",
    "        aws_secret_access_key='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',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        # session.get_credentials().__dict__,\n",
    "        # session.get_available_regions('ec2'),\n",
    "        # session.get_available_resources(),\n",
    "        # session.get_available_services()\n",
    "    )\n",
    "\n",
    "    ec2 = session.resource('ec2')\n",
    "    s3 = session.resource('s3')\n",
    "\n",
    "    # print(ec2)\n",
    "    assert ec2 is not None, \"User doesn't have access to ec2 resource\"\n",
    "    # print(ec2.instances)\n",
    "    # print(ec2.instances.all())\n",
    "    # assert not ec2.instances , \"No ec2 instance observed\"\n",
    "    \n",
    "    # instance = create_instance(ami_id='ami-00eb20669e0990cb4')\n",
    "    \n",
    "\n",
    "    # assert instance is not None, \"Instance creation failed\"\n",
    "\n",
    "    print(ec2.describe_instances())\n",
    "    # for instance in ec2.instances.all():\n",
    "        # if instance.state['Name'] in ['running','stopped']:\n",
    "            # terminate_instance(instance.id)\n",
    "        \n",
    "        # print(instance.state,instance.id)\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    for bucket in s3.buckets.all():\n",
    "        print (bucket.name)\n",
    "        for item in bucket.objects.all():\n",
    "            print (\"\\t%s\" % item.key)\n",
    "        \n",
    "\n",
    "    result = create_bucket('my-sample')\n",
    "\n",
    "        \n",
    "    upload_objects_to_s3()\n",
    "\n",
    "except:\n",
    "    logger.critical('Exception caught')\n",
    "    traceback.print_exc(file=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PRE-REQUISITES - configure the aws account & region by passing access key and secret key via aws configure\n",
    "\n",
    "import boto3\n",
    "\n",
    "ec2 = boto3.resource('ec2')\n",
    "\n",
    "for instance in ec2.instances.all():\n",
    "    print (instance.id, instance.state)\n",
    "\n",
    "def create_instance(ami_id,size='t2.micro')\n",
    "    instance = ec2.create_instances(\n",
    "        ImageId=ami_id, # free-tier Linux AMI\n",
    "        MinCount=1,\n",
    "        MaxCount=1,\n",
    "        InstanceType=size)\n",
    "\n",
    "create_instance(ami_id='ami-8c122be9')\n",
    "\n",
    "def terminate_instance(instance_id):\n",
    "    instance = ec2.Instance(instance_id)\n",
    "    result = instance.terminate()\n",
    "    print(result)\n",
    "\n",
    "terminate_instance('i-0045fe319d1235d6a')\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "for bucket in s3.buckets.all():\n",
    "    print (bucket.name)\n",
    "    for item in bucket.objects.all():\n",
    "        print (\"\\t%s\" % item.key)\n",
    "        \n",
    "def create_bucket(bucket_name):\n",
    "    import traceback\n",
    "    import sys\n",
    "    import datetime\n",
    "    try:\n",
    "        print(s3)\n",
    "        today_date = datetime.datetime.today().strftime('%Y-%d-%m')\n",
    "        bucket_name = bucket_name + '-' + today_date\n",
    "        result = s3.create_bucket(\n",
    "                                    Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration={'LocationConstraint': 'us-east-2'}\n",
    "                                 )\n",
    "        print(result)\n",
    "        return result\n",
    "    except :\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "result = create_bucket('my-sample')\n",
    "\n",
    "import traceback\n",
    "def upload_objects_to_s3():\n",
    "    try:\n",
    "        from pathlib import WindowsPath\n",
    "        path = WindowsPath(r'D:\\PyCharmProjects\\Input data')\n",
    "        object_name = str(path / 'advertising.csv')\n",
    "        print(object_name)\n",
    "        response = s3.Object(result.name, object_name).put(Body=open(str(object_name), 'rb'))\n",
    "        print(response)\n",
    "    except :\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        \n",
    "upload_objects_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUI programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use buttons to upload/download to/from a database\n",
    "import tkinter as tk\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc\n",
    "import os\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "\n",
    "master = tk.Tk()\n",
    "master.minsize(300,100)\n",
    "master.title('Uploading a file to Postgre database')\n",
    "\n",
    "config = {\n",
    "'user': 'postgres',\n",
    "'password': 'postgres',\n",
    "'host': '127.0.0.1',\n",
    "'port': '5432',\n",
    "'database': 'postgres'\n",
    "}\n",
    "\n",
    "def upload():\n",
    "    print(\"uploading started...\")    \n",
    "    titanic = pd.read_csv(os.path.join(path,'titanic.csv'))\n",
    "    titanic.to_sql(name='loan_data', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "def download():\n",
    "    print('downloading started...')\n",
    "    titanic_backup = pd.read_sql(sql='select * from titanic',con=engine)\n",
    "    titanic_backup.to_csv(os.path.join(path,'titanic_backup.csv'),index=False)\n",
    "    print('downloading finished')\n",
    "\n",
    "\n",
    "engine = create_engine('postgresql://'+config['user']+':'+config['password']+'@'+config['host']+':'+config['port']+'/'+config['database'],echo=False)\n",
    "print(engine)\n",
    "path = r'M:\\PythonSpace\\Datasets'\n",
    "\n",
    "b1 = tk.Button(master, text=\"Upload\", command=upload,height=5,width=10,bg='orange') # creates a button widget with the specified height and width\n",
    "b2 = tk.Button(master, text=\"Download\", command=download,height=5,width=10,bg='grey') # creates a button widget with the specified height and width\n",
    "b1.pack() # to pack the widget @ default location\n",
    "b2.pack() # to pack the widget @ default location\n",
    "\n",
    "# b1.place(x=20, y=20) # to pack the widget @ customized location\n",
    "# b2.place(x=100, y=100) # to pack the widget @ customized location\n",
    "\n",
    "# waits for events\n",
    "master.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threading ::: for concurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "def sleeper(i):\n",
    "    print (\"thread %d sleeps for 5 seconds\" % i)\n",
    "    time.sleep(5)\n",
    "    print (\"thread %d woke up\" % i)\n",
    "\n",
    "for i in range(10):\n",
    "    t = Thread(target=sleeper, args=(i,))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Anaconda\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-1-bef282b00d3c>\", line 4, in dummy\n",
      "    time.sleep(5)\n",
      "NameError: name 'time' is not defined\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of program\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def dummy():\n",
    "    time.sleep(5)\n",
    "\n",
    "def get_process_stats():\n",
    "    # to monitor process statistics\n",
    "    import psutil\n",
    "    import pandas as pd\n",
    "    processes = []\n",
    "    for item in list(psutil.win_service_iter()):\n",
    "        processes.append( psutil.win_service_get(item.name()).as_dict() )\n",
    "    df = pd.DataFrame(processes)\n",
    "    required = df[['display_name','start_type','status']]\n",
    "    required.to_csv('report.csv',index=False)\n",
    "    \n",
    "t1 = threading.Thread(target=dummy)\n",
    "t2 = threading.Thread(target=get_process_stats)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print('end of program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class MyThread(threading.Thread):\n",
    "    def __init__(self,name='Sample',counter=0):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.thread_id = counter\n",
    "        self.name = name\n",
    "    def run(self):\n",
    "        print(\"\\nStarting \" + self.name)\n",
    "        print_date(self.name, self.thread_id)\n",
    "        print(\"Exiting \" + self.name)\n",
    "\n",
    "def print_date(threadName, counter):\n",
    "    print(\"{}[{}]: {}\".format( threadName, counter, datetime.now().strftime('%d-%m-%Y %H:%M:%S') ))\n",
    "    time.sleep(5)\n",
    "    print(\"{}[{}]: {}\".format( threadName, counter, datetime.now().strftime('%d-%m-%Y %H:%M:%S') ))\n",
    "    \n",
    "    \n",
    "threads = []\n",
    "# Create new threads\n",
    "thread1 = MyThread(\"Thread\", 1)\n",
    "thread2 = MyThread(\"Thread\", 2)\n",
    "\n",
    "# Start new Threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "threads.extend([thread1,thread2])\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"\\nExiting the Program!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class MyThread(threading.Thread):\n",
    "    def __init__(self,name='Sample',counter=0):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.thread_id = counter\n",
    "        self.name = name\n",
    "    def run(self):\n",
    "        print(\"\\nStarting \" + self.name)\n",
    "        thread_lock.acquire()\n",
    "        print_date(self.name, self.thread_id)\n",
    "        thread_lock.release()\n",
    "        print(\"Exiting \" + self.name)\n",
    "\n",
    "def print_date(threadName, counter):\n",
    "    print(\"{}[{}]: {}\".format( threadName, counter, datetime.now().strftime('%d-%m-%Y %H:%M:%S') ))\n",
    "    time.sleep(5)\n",
    "    print(\"{}[{}]: {}\".format( threadName, counter, datetime.now().strftime('%d-%m-%Y %H:%M:%S') ))\n",
    "    \n",
    "threads = []\n",
    "\n",
    "# create a new lock object\n",
    "thread_lock = threading.Lock()\n",
    "\n",
    "# Create new threads\n",
    "thread1 = MyThread(\"Thread\", 1)\n",
    "thread2 = MyThread(\"Thread\", 2)\n",
    "\n",
    "# Start new Threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "threads.extend([thread1,thread2])\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"\\nExiting the Program!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiprocessing - run processes in multiple cores / multiple CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before creating process [0, 0, 0, 0, 0, 0, 0, 0, 0] 0\n",
      "Main process id : 2640 Child process id : 26256\n",
      "After process completion [0, 0, 0, 0, 0, 0, 0, 0, 0] 0\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from random import choice\n",
    "import os\n",
    "\n",
    "def process_data(elements,shared_array,sum_of_elements):\n",
    "    print('Inside function',shared_array,sum_of_elements.value)\n",
    "    for index,value in enumerate(elements):\n",
    "        shared_array[index] = value\n",
    "    sum_of_elements.value = sum(shared_array)\n",
    "    print('Inside the function',shared_array[:],sum_of_elements.value)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    elements = list(range(1,10))\n",
    "    # create shared collection/container - used by both main and child process\n",
    "    shared_array = mp.Array('i',len(elements))\n",
    "    # create shared scalar value - used by both main and child process\n",
    "    sum_of_elements = mp.Value('i') \n",
    "    print('Before creating process',shared_array[:],sum_of_elements.value)\n",
    "    p1 = mp.Process(target=process_data,args=(elements,shared_array,sum_of_elements))\n",
    "    p1.start()\n",
    "    print('Main process id :',os.getpid(),'Child process id :',p1.pid)\n",
    "    p1.join()\n",
    "    print('After process completion',shared_array[:],sum_of_elements.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### psutil - get a report of all processes running in Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import pandas as pd\n",
    "processes = []\n",
    "for item in list(psutil.win_service_iter()):\n",
    "    processes.append( psutil.win_service_get(item.name()).as_dict() )\n",
    "df = pd.DataFrame(processes)\n",
    "print(df.columns)\n",
    "required = df[['display_name','start_type','status']]\n",
    "print(required)\n",
    "required.to_csv('report.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web automation using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PRE-REQUISITES : webdriver for browser to be installed - \n",
    "# chromedriver for Chrome browser, geckodriver for Firefox browser, e.t.c\n",
    "\n",
    "# using chrome\n",
    "import os\n",
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "web_driver_path = os.path.join(r'M:\\Drivers','chromedriver.exe')\n",
    "browser = webdriver.Chrome(executable_path=web_driver_path, options=options)\n",
    "browser.get(r'https://www.google.com/')\n",
    "browser.close()\n",
    "\n",
    "\n",
    "# get your latest orders from amazon\n",
    "import os\n",
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "web_driver_path = os.path.join(r'M:\\Drivers','chromedriver.exe')\n",
    "browser = webdriver.Chrome(executable_path=web_driver_path, options=options)\n",
    "\n",
    "sign_in_url = r'https://www.amazon.com/gp/navigation/redirector.html/ref=sign-in-redirect?ie=UTF8&associationHandle=usflex&currentPageURL=https%3A%2F%2Fwww.amazon.com%2F%3Fref_%3Dnav_signin&pageType=Gateway&switchAccount=&yshURL=https%3A%2F%2Fwww.amazon.com%2Fgp%2Fyourstore%2Fhome%3Fie%3DUTF8%26ref_%3Dnav_signin'\n",
    "browser.get(sign_in_url)\n",
    "browser.implicitly_wait(time_to_wait=5)\n",
    "\n",
    "email_id = browser.find_element_by_xpath('//input[@type=\"email\"][@id=\"ap_email\"]')\n",
    "email_id.send_keys(r'manojkumar.rajendran@outlook.com')\n",
    "continue_button = browser.find_element_by_xpath('//input[@type=\"submit\"][@id=\"continue\"]')\n",
    "continue_button.submit()\n",
    "\n",
    "browser.implicitly_wait(time_to_wait=5)\n",
    "\n",
    "password = browser.find_element_by_xpath('//input[@type=\"password\"][@id=\"ap_password\"]')\n",
    "password.send_keys(r'Mano@111085')\n",
    "sign_in_button = browser.find_element_by_xpath('//input[@type=\"submit\"][@id=\"signInSubmit\"]')\n",
    "sign_in_button.submit()\n",
    "\n",
    "\n",
    "# using firefox \n",
    "import os\n",
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "# the absolute path of firefox webdriver\n",
    "web_driver_path = os.path.join(r'C:\\Users\\Manojkumar.Rajendran\\Downloads','geckodriver.exe')\n",
    "browser = webdriver.Firefox(executable_path=web_driver_path, options=options)\n",
    "\n",
    "risk_url = r'https://devriskid360.aceprs.com/Account/LogOn?ReturnUrl=%2F'\n",
    "browser.get(risk_url)\n",
    "username = browser.find_element_by_xpath('//input[@id=\"UserName\"]')\n",
    "password = browser.find_element_by_xpath('//input[@id=\"Password\"]')\n",
    "logon = browser.find_element_by_xpath('//button[@type=\"submit\"][@class=\"btn btn-default\"]')\n",
    "username.send_keys('PHSKXS2')\n",
    "password.send_keys('Happy123!')\n",
    "logon.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### automated test suite using pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pytest -v <file> to know verbose output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def test_display():\n",
    "    assert 'Hello' == 'hello'\n",
    "\n",
    "def test_sets():\n",
    "    \"\"\"Test sets\"\"\"\n",
    "    assert set('1308') == set('8035')\n",
    "\n",
    "def f():\n",
    "    raise SystemExit(1)\n",
    "\n",
    "def test_mytest():\n",
    "    # check if a function raises a particular exception\n",
    "    with pytest.raises(SystemExit):\n",
    "        f()\n",
    "\n",
    "#### using pytest fixtures\n",
    "# scope can be class,module,function or session\n",
    "@pytest.fixture(scope='function') # use pytest -s <file.py> command switch\n",
    "def my_fixture():\n",
    "    config = {}\n",
    "    config['strategy'] = input('Enter the strategy')\n",
    "    return config\n",
    "\n",
    "def test_fixture(my_fixture):\n",
    "    print('Inside test_fixture')\n",
    "    assert my_fixture['strategy'] == 'MongoReader'\n",
    "\n",
    "###########################################################\n",
    "import pytest\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "@pytest.fixture()\n",
    "def cleandir():\n",
    "    newpath = tempfile.mkdtemp()\n",
    "    print(newpath)\n",
    "    os.chdir(newpath)\n",
    "\n",
    "\n",
    "@pytest.mark.usefixtures(\"cleandir\")\n",
    "class TestDirectoryInit:\n",
    "    def test_cwd_starts_empty(self):\n",
    "        assert os.listdir(os.getcwd()) == []\n",
    "        with open(\"myfile\", \"w\") as f:\n",
    "            f.write(\"hello\")\n",
    "\n",
    "    def test_cwd_again_starts_empty(self):\n",
    "        assert os.listdir(os.getcwd()) == []\n",
    "\n",
    "\n",
    "###########################################################\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"num, output\",[(1,11),(2,22),(3,35),(4,44)])\n",
    "def test_multiplication_11(num, output):\n",
    "    assert 11*num == output\n",
    "        \n",
    "###########################################################\n",
    "\n",
    "@pytest.fixture(params=[\n",
    "    # Tuples with password string and expected result\n",
    "    ('password', False),\n",
    "    ('p@ssword', False),\n",
    "    ('p@ssw0rd', True)\n",
    "])\n",
    "def password(request):\n",
    "    \"\"\"Password fixture\"\"\"\n",
    "    return request.param\n",
    "\n",
    "\n",
    "def password_contains_number(pwd):\n",
    "    \"\"\"Checks if a password contains a number\"\"\"\n",
    "    return any([True for x in range(10) if str(x) in pwd])\n",
    "\n",
    "\n",
    "def password_contains_symbol(pwd):\n",
    "    \"\"\"Checks if a password contains a symbol\"\"\"\n",
    "    return any([True for x in '!,@,#,$,%,^,&,*,(,),_,-,+,='.split(',') if x in pwd])\n",
    "\n",
    "\n",
    "def check_password(pwd):\n",
    "    \"\"\"Check the password\"\"\"\n",
    "    return password_contains_number(pwd) and password_contains_symbol(pwd)\n",
    "\n",
    "\n",
    "def test_password_verifier_works(password):\n",
    "    \"\"\"Test that the password is verified correctly\"\"\"\n",
    "    (pwd, result) = password\n",
    "    print ('\\n')\n",
    "    print (pwd,result)\n",
    "\n",
    "    assert check_password(pwd) == result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encrypt and decrypt a string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# solution 1\n",
    "import base64\n",
    "# returns a bytes object\n",
    "base64.b64encode(b'password')\n",
    "base64.b64decode(b'cGFzc3dvcmQ=')\n",
    "# to decode the bytes to string\n",
    "base64.b64decode(b'cGFzc3dvcmQ=').decode()\n",
    "\n",
    "\n",
    "# solution 2\n",
    "from Crypto.Cipher import AES\n",
    "from os import urandom\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "def encrypt_message(message):\n",
    "    while len(message) % 16 != 0:\n",
    "        message = message + ' '\n",
    "    return cipher.encrypt(message)\n",
    "\n",
    "def decrypt_message(message):\n",
    "    message = cipher.decrypt(message)\n",
    "    message = message.decode('utf-8')\n",
    "    return message\n",
    "\n",
    "def validate_id(reference_id):\n",
    "    try:\n",
    "        assert len(reference_id) == 12, \"Reference id not equals 12 chars\"\n",
    "        assert any([item.isnumeric() for item in list(reference_id)]),\"Reference id doesn't contain any number\"\n",
    "        assert any([item.islower() for item in list(reference_id)]), \"Reference id doesn't contain any alphabet\"\n",
    "        assert any([item in list('$#@') for item in list(reference_id)]), \"Reference id contains invalid special character\"\n",
    "\n",
    "    except AssertionError:\n",
    "        print('One of validations fails')\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        return False\n",
    "\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "key = urandom(16)\n",
    "iv = urandom(16)\n",
    "cipher = AES.new(key, AES.MODE_ECB, iv)\n",
    "\n",
    "while True:\n",
    "    reference_id = input('Enter your reference id of 12 chars :')\n",
    "    if reference_id == 'stop':\n",
    "        break\n",
    "    if validate_id(reference_id):\n",
    "        print('All validation passes. Encrypting your reference id...')\n",
    "        encrypted_message = encrypt_message(reference_id)\n",
    "        print('Your reference id after encryption is :',encrypted_message)\n",
    "        choice = input('Do you want to display your original reference id ?. Say Y for Yes and N for No :')\n",
    "        if choice == 'Y':\n",
    "            print('Your reference id is :',decrypt_message(encrypted_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading a tar.gz file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from pathlib import WindowsPath\n",
    "path = WindowsPath(r'D:\\PyCharmProjects\\Input data')\n",
    "filename = 'seaborn-0.9.0.tar.gz'\n",
    "tar_gz_file = tarfile.open(path / filename, \"r:gz\")\n",
    "names = list(tar_gz_file.getnames())\n",
    "basename = filename.split('.tar.gz')[0]\n",
    "root_names = [item.split(basename)[1] for item in names]\n",
    "root_names = [item.split('/')[1] for item in root_names if '/' in item]\n",
    "print(set(root_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### populate values onto MS word template file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from docxtpl import DocxTemplate\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "path = r'C:\\Users\\Manojkumar.Rajendran\\Desktop'\n",
    "\n",
    "# template\n",
    "template = os.path.join(path,'template.docx')\n",
    "# data\n",
    "data_file = os.path.join(path,'employee_data.xlsx')\n",
    "\n",
    "employee_data = pd.read_excel(data_file)\n",
    "\n",
    "letter_date = datetime.datetime.today().strftime('%d/%b/%Y')\n",
    "\n",
    "for index,row in employee_data.iterrows():\n",
    "    doc = DocxTemplate(template)\n",
    "    ref_no = row['LETTER_REF_NUMBER']\n",
    "    emp_name = row['EMP_NAME']\n",
    "    emp_id = row['EMP_ID']\n",
    "    short_name = row['SHORT_NAME']\n",
    "    appraisal_rating = row['NEW_RATING']\n",
    "    ctc = row['NEW_CTC_INR']\n",
    "    in_words = row['NEW_CTC_WORDS']\n",
    "    designation = row['NEW_DESIGNATION']\n",
    "    level = row['NEW_DESIGNATION_LEVEL']\n",
    "    basic_monthly = row['MONTHLY_BASIC']\n",
    "    basic_annual = row['ANNUAL_BASIC']\n",
    "    hra_monthly = row['MONTHLY_HRA']\n",
    "    hra_annual = row['ANNUAL_HRA']\n",
    "    total_a_monthly = row['MONTHLY_TOTAL_A']\n",
    "    total_a_annual = row['ANNUAL_TOTAL_A']\n",
    "    fuel_reimb_monthly = row['MONTLY_FUEL_REIMB']\n",
    "    fuel_reimb_annual = row['ANNUAL_FUEL_REIMB']\n",
    "    comm_reimb_monthly = row['MONTHLY_COMMUNICATION_REIM']\n",
    "    comm_reimb_annual = row['ANNUAL_COMMUNICATION_REIM']\n",
    "    lta_monthly = row['MONTHLY_LTA']\n",
    "    lta_annual = row['ANNUAL_LTA']\n",
    "    total_b_monthly = row['MONTHLY_TOTAL_B']\n",
    "    total_b_annual = row['ANNUAL_TOTAL_B']\n",
    "    spcl_alwnce_monthly = row['MONTHLY_SPECIAL_ALLOWANCE_C']\n",
    "    spcl_alwnce_annual = row['ANNUAL_SPECIAL_ALLOWANCE_C']\n",
    "    gross_d_monthly = row['MONTHLY_TOTAL_GROSS_D']\n",
    "    gross_d_annual = row['ANNUAL_TOTAL_GROSS_D']\n",
    "    pf_monthly = row['ANNUAL_PF_CONTRIBUTION'] / 12\n",
    "    pf_annual = row['ANNUAL_PF_CONTRIBUTION']\n",
    "    gratuity_monthly = row['ANNUAL_GRATUITY'] / 12\n",
    "    gratuity_annual = row['ANNUAL_GRATUITY']\n",
    "    ctc_minus_de_mon = (ctc/12) - (gross_d_monthly+pf_monthly+gratuity_monthly)\n",
    "    ctc_minus_de_annual = ctc - (gross_d_annual+pf_annual+gratuity_annual)\n",
    "    \n",
    "    context = {'letter_date' : letter_date,\n",
    "            'ref_no': ref_no,\n",
    "            'emp_name' : emp_name,\n",
    "            'emp_id' : emp_id,\n",
    "            'short_name' : short_name,\n",
    "            'appraisal_rating' : appraisal_rating,\n",
    "            'ctc' : ctc,\n",
    "            'in_words' : in_words,\n",
    "            'designation' : designation,\n",
    "            'level' : level,\n",
    "            'basic_monthly' : basic_monthly,\n",
    "            'basic_annual' : basic_annual,\n",
    "            'hra_monthly' : hra_monthly,\n",
    "            'hra_annual' : hra_annual,\n",
    "            'total_a_monthly' : total_a_monthly,\n",
    "            'total_a_annual' : total_a_annual,\n",
    "            'fuel_reimb_monthly' : fuel_reimb_monthly,\n",
    "            'fuel_reimb_annual' : fuel_reimb_annual,\n",
    "            'comm_reimb_monthly' : comm_reimb_monthly,\n",
    "            'comm_reimb_annual' : comm_reimb_annual,\n",
    "            'lta_monthly' : lta_monthly,\n",
    "            'lta_annual' : lta_annual,\n",
    "            'total_b_monthly' : total_b_monthly,\n",
    "            'total_b_annual' : total_b_annual,\n",
    "            'spcl_alwnce_monthly' : spcl_alwnce_monthly,\n",
    "            'spcl_alwnce_annual' : spcl_alwnce_annual,\n",
    "            'gross_d_monthly' : gross_d_monthly,\n",
    "            'gross_d_annual' : gross_d_annual,\n",
    "            'pf_monthly' : pf_monthly,\n",
    "            'pf_annual' : pf_annual,\n",
    "            'gratuity_monthly' : gratuity_monthly,\n",
    "            'gratuity_annual' : gratuity_annual,\n",
    "            'ctc_minus_de_mon' : ctc_minus_de_mon,\n",
    "            'ctc_minus_de_annual' : ctc_minus_de_annual\n",
    "    }\n",
    "    doc.render(context)\n",
    "    output_file_name = f'{emp_id}_2018_19_appraisal_letter.docx'\n",
    "    doc.save(os.path.join(path,output_file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
